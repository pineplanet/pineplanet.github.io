---
title: TIL 2022-02-03 python 딥러닝
tags: [TIL, python]
categories: TIL
---

# 오늘 배운 것 

- Dense Layer기반 Image 분류의 문제점 
  - 분류하려는 이미지가 고정된 위치에 있어야 함.
    - flatten 으로 1차원 컬럼으로 feature 를 input 으로 하니까 
  - 이미지가 커질수록 많은 weight가 필요해짐 
- object detection : object 의 위치를 찾아냄 
  - localization :   1 object 가 1 image 에 있는 것 (bounding box)
  - Detection : 1 image 안에 여러 object 가 있고, 박스 형태로 찾아 내는 것 (bounding box)
  - segmentation : 픽셀 단위로 object 를 판단해 냄 
  - object detection 구성 요소 
    - 영역 추정 
      - object 가 있을 만한 위치 찾기
      - 밝기, 색상, 윤곽선 등의 특성이 유사한 region -> 그룹핑 -> 오브젝트 후보 영역 찾기 
      - selective search 알고리즘 
    - 네트워크 구성 
      - feature extraction (backbone)
      - fpn (neck)
      - network prediction (head)
    - IOU(intersection over union)
      - object detection 성능 평가 
    - NMS
      - 확실한 바운딩 박스 뺴고 나머지를 눌러주는 (?) 알고리즘 
      - 두개의 threshold 값 (confidence , Ioc)
        - confidence 값이 높은 박스와 영역 겹치는 박스 찾고 , Ioc 값을 확인 -> 특정 값 이상 이면 제거 
    - mAP
    - Anchor box ...
  - object detection 난제 
    - 분류, 회귀 동시에 해결 해야함  -> loss 함수가 복잡 
    - 이미지에 다양한 형태의 오브젝트가 섞임
    - 수행 시간 
    - 전체 이미지 >>>> 오브젝트 크기 
    - 데이터 세트 부족 
  - 정밀도 , 재현율 
    - 예측 = 실제 값 비율 (TP/FP+TP)
    - 재현율 : 예측 대상을 빼먹지 않고 예측 했는지 (TP/FN+TP)
    - 오차 행렬 
      - 4분면 matrix ( 예측 클래스 , 실제클래스 )
        - TN : 실제 n , 예측을 n
        - fp: 실제 n, 예측 p 
        - fn : 예측 n , 실제 p (오브젝트 예측 안된것)
        - tp : 예측 p , 실제 p
    - mAP
  - 주요 데이터셋 
    - PASCAL VOC
    - MS COCO
    - Google Open Images
  - R-CNN
    - stage 1 : selective search 적극 활용 Region Proposal (2000개 뽑음, 사이즈 맞춤)
    - stage 2 : 2000개 이미지 학습
        - background 도 학습 fine tuning
        - 1D flattened 로 압축
        - fc layer output까지가 deep learning
        - bounding box regression : proposal 의 중심점 과 ground Truth 의 중점 차이를 줄이기 
    - svm classifier 
    - 장단점: 
      - 장 : 높은 정확도 
      - 단 : 너무 느림, 복잡함, crop, warp
  - SPP(Spatial Pyramid Pooling ) Net
    - 원본이미지를 feature map + selective search 한 것을 맵핑  -> 안됨! 왜냐면 feature 맵이 3차원 + 사이즈를 정확히 고정 시킬 수 가 없음 => 딥러닝을 위한 flatten을 시킬 수 가 없음
    - 위의 문제를 해결하기 위한 spp layer ! 
    - bag of words : 이미지의 부분들을 다 쪼갬 -> 부분들을 분석해서 분류 (histogram) -> 원본의 정보를 새로운 맵핑 정보로 삼음 
    - spm : 문맥 (?) 파악을 위해 위치 정보 + bag of words 활용 -> 새로운 feature 생성 ! 
    - feature map 의 크기와 상관 없이 분면 단위의 feature로 나오니까 input size 를 고정 할 수 있음 
  - Fast R-CNN 
    - spp layaer -> ROI pooling layer , 하나의 이미지에서 만들어진 feature 들에 ROI Pooling 적용 (selective search) 
    - svm -> softmax 적용 
    - Multi-task loss 함수 로 classification, Regression 함께 최적화
  - faster R-CNN
    - 딥러닝 만으로 오브젝트 디텍션! 
    - ss - ROI -> Region Proposal Network 
      - 구현 이슈  : ss는 있을만한 위치를 모두 알려주는데 ..
        - feature sms pixel, target 은 ground Truth box 인데 어떻게 트레이닝? 
          - anchor box 개념을 도입 (여러형태의 겹치는 박스들..0.5,1,2)
          - 이미지의 전체 1/16 크기 feature map 이라면 => 그리드 포이트 별로 맵핑!
          - 이미지 바깥의 anchor는 제외 
    - RPN
      - anchor box -> 
      1. 3X3 512 channel -> 1*1 conv 9 output channel -> 이진 분류(오브젝트?)
         - 1*1 conv ? feature map 파라미터 줄이면서 차원 축소(depth 변화)
      2. 3X3 512 channel -> 영역추천 RPN Bounding Box Regression 
        - anchor box 를 ref로 이용, 
        - ground truth와 예측 box 의 거리 차이 (x, y, w, h)  와 
        - ground truth와 ahcore box 의 거리 차이 (x, y, w, h) 차이가 최대한 동일하게 예측 되어야 함
        - positive / negative anchor box 
          - ground truth bb 겹치는 값으로 판단 
            - 가장 높으면 positive
            - 0.7 이상 : positive
            - 0.3 이하 : negative 
        - RPN loss 함수 
    - object detection 구현 
      - opencv DNN 
        - 장단점 
          - 장점 : 쉽게 구현 가능 
          - 단점 : gpu 지원 약함, 모델 학습 안되고, inference 만 가능 
  - 모던 object Detection 모델 아키텍쳐 
    - 구조 
      - backbone
        - ResNet 이미지 분류 모델 원본이미지 -> 추상화된 feature map (bottom - up)
      - neck 
        - FPN backbone -> object detection 하기 위한 정보를 추출 (top-down)
        - 상위 feature 맵의 추상화된 정보와 하위 맵의 정보 결합 
      - head 
        - classification, bbox regression
      - 종류
        - Feature Pyramid Network
        - MMDetection 패키지의 모델 아키텍처
        - YOLO V3 모델 아키텍처
      
  - Segmentation (의미 있는 분할)
    - semantic -> 동일 한 클래스 를 합쳐서 봄 픽셀 단위로 classification 
      - Encoder-Decorder Model
          - 원본이미지를 압축 -> 압축해제 : 원본이미지에서 찾을 수 없었던 것을 찾아냄(?)
            - Mask R-CNN : Faster R-CNN + FCN
    - instance -> 동일한 클래스 의 오브젝트를 분리 해서 봄 (FR + FCN )
    - pytorch 기반 패키지 
      - torchvision 
      - detectron2 
      - mmdetection -> 지원 알고리즘이 많음
    - mmdetection : 칭화대 openMMlab -> 발전 
      - 개요 
        - 뛰어난 성능, 효율적인 모듈, config 기반 덕분에 간편한 파이프라인 구축 
        - MMDetection: Open MMLab Detection Toolbox and Benchmark
        - 백본 지원, OD, Segmentation 지원 
      - 아키텍쳐 
        - backbone : feature Extractor (이미지 -> feature map)
        - neck (FPN, PFP...) head 와 연결, 정제 작업
        - denseHead : object 위치 , classification
        - RoIExtractor 
        - RoIHead
      - 주요 구성요소 
        - CONFIG = Dataset Config -> Data Pipeline Config -> Model Config -> Data Pipeline Config -> Train/Valid/Test Config
        - Dataset -> pipleine -> model -> pipeline -> 학습, 검증, 테스트 
        - pipeline 
          - hook(callback) 으로 학습에 필요한 설정 customization
          - Start -> <before train epoch: DistSamplerHook>(TRAINING EPOCH: <before train iter: LrUpdaterHook, IterTimerHook>Loop(Model forward) <after train iter: OptimizerHook, IterTimerHook, LoggerHook>) <after train epoch: CheckpointHook, EvalAPHook> -> end
        - OpenMMLab Project: 
          - MMCV
          - MMDetection, 
          - MMSegmentation