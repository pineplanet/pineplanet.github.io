---
title: TIL 2022-01-26 python 머신러닝
tags: [TIL, python]
categories: TIL
---

- 머신러닝 
  - 1 확률적 경사 하강법 ▶️경사 하강법 알고리즘을 이해하고 대량의 데이터에서 분류 모델을 훈련하기
    - 확률적(== 랜덤, 무작위) + 경사 (기울기) + 하강법(내려가는 방법) : 가장 가파른 경사를 조금씩 내려감
      - 경사? 
        - 손실 함수 : 머신러닝 알고리즘이 얼마나 나쁜지 측정하는 함수 
        - 손실함수의 값이 낮을 수록 최적값 
        - 손실함수의 경사를 내려오면서 최적값을 찾는 것이 확률적 경사 하강법 
          - 분류 일 경우 : 정확도는 손실함수로 측정할 수 없다.(미분 가능하지 않다.) -> 로지스틱 손실 함수(이진 크로스 엔트로피 손실함수) 사용
            - 예측 값 * 정답 -> 음수를 곱함 :
              - 예측 값이 높으면 낮은 값으로 변환 
              - 예측 값이 낮으면 높은 값으로 변환 
              - 타겟이 음성클래스 일 경우 
                - 양성 클래스 값으로 바꿔서 계산 
            - 로그로 변환 할 수도 있음 
              - target =1 : -log(예측확률 )
              - target =0 : -log(1-예측확률)
          - 회귀 일 경우 : 평균 절댓값 오차, 평균 제곱 오차 
      - 훈련세트에서 샘플을 하나씩(하이퍼 파라미터) 꺼내서 훈련 반복 -> 훈련세트를 모두 사용 하면 1에포크 완료 
        - 여러개씩 꺼내기 : 미니배치 경사 하강법
        - 모두 꺼내기 : 배치 경사 하강법
      - 여러 에포크 반복
    - 점진적인 학습(유사 개념 : 온라인 학습)
      - 만든 모델을 유지 하면서 데이터 셋을 업데이트 할 수 없을까?
    - 데이터 전처리
      - 각 특성 마다 스케일이 같아야 한다.( 각 특성의 경사를 공평하게 판단할 수 있도록 )
    - SGDClassifier
      - loss : 머신러닝 모델 지정 (예 : log -> 로지스틱 손실, 로지스틱 회귀 모델)
      - max_iter : 에포크 
      - partial_fit : 기존 학습한 w,b 유지 하면서 다시 학습
    - 에포크와 과대/과소적합
      - 규제가 커질수록 과소 적합 
      - 규제가 작아질수록 과대 적합 
      - 에포크도 너무 커지면 과대 적합 
      - 에포크가 너무 작으면 과소 적합
      - 조기 종료 
  - 2 결정 트리
    - 질문으로 데이터 훈련세트를 양쪽으로 나누는 것 (스무고개 처럼)
      - 로지스틱 회귀로 와인 분류하기
      - 결정 트리
        - 지니불순도 : 
          - 지니 : criterion(어떤 기준으로 노드를 나눌 것인가)의 기본값, 차이가 가장 크게 나오는 방향으로 나눔
          - 계산 : 1 - (음성클래스 비율제곱 - 양성클래스 비율 제곱 )
          - 리프노드가 모두 순수 노드가 될때까지 분할 -> 이경우 과대 적합 될 수 도 있어서 -> 가지치기 
          - 부모노드와 자식노드의 불순도 차이 확인 
        - 가지치기 
          - 많은 매개 변수가 있지만 단순하게는 max_depth로 제한 
    - 트리 -> 앙상블 모델 
  - 3 교차 검증과 그리드 서치 ▶️검증 세트가 필요한 이유를 이해하고 교차 검증해 보기
    - 검증 세트
      - train, test set 뿐 아니라 검증 세트도 나눠야함. 
      - 테스트 세트는 실전에 투입하기 직전에 성능을 예측하기 위한 것이므로(아껴써야...)
      - 훈련을 위한 모델링을 하면서 튜닝하기 위해서 사용하는 데이터셋을 검증세트를 사용
      - 나중에 테스트하기 전에 train set + 검증 세트 를 합쳐서 최종모델을 한번 더 훈련
    - 교차 검증
      - 훈련세트의 데이터가 크지 않을 경우, 검증 세트를 나누기 부담 스러울 수 있음 
      - 이경우 훈련세트를 여러개로 나눠서(폴드), 훈련 세트와 검증 세트를 임의(또는 순차적)으로 바꿔가면서 모델 평가를 함 
      - 예 : 1,2,3 세트 중 
        - 1 ,2 훈련 / 3 검증 -> 평가 
        - 1,3 훈련 / 2 검증 -> 평가 
        - 2,3, 훈련/ 1 검증 -> 평가 
        - 평가 점수 평균
    - 하이퍼파라미터 튜닝


