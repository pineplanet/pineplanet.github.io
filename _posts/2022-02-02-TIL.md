---
title: TIL 2022-02-02 python 딥러닝
tags: [TIL, python]
categories: TIL
---

# 오늘 배운 것 

- 활성화 함수(Activation Function)의 이해
  - 종류 
    - 전통 : sigmoid 
      - 이진 분류 시 마지막 classification 출력층에 보통 사용
      - 문제 : 
        - 입력 값이 양으로 크게 커져도 출력값에 변화가 없어서 미분 할 수 없음 -> Gradient 도 0 -> weight update 를 할 수 없음
        - 평균이 0이 아니어서 gradient update 가 지그재그
    - Hyperbolic Tangent
      - sigmoid 와 유사
      - -1과 1 사이 값을 출력 해서 평균이 0이 될 수 있다.
      - 그러나 sigmoid 의 문제점이 여전히 있어서 입력양이 늘어나도 미분 할 수 없다.
    - Rectified Linear Unit(ReLu)
      - 직선 형태 
      - MIT Introduction to Deep learning 강의 들어볼 것 
      - 은닉층에 사용됨 
      - 입력값이 0보다 작으면 출력은 0 , 0보다 크면 입력값 출력 -> 미분 할 수 있다.
    - softmax activation 
      - sigmoid 와 유사 (0~ 1까지 확률값)
      - 여러개의 값을 출력 해줌
      - 개별 출력 값의 총합이 1이 되도록 맵핑 해줌 
    
  - 목적 
    - 딥러닝 네트워크에 비선형성을 적용하기 위해서 
    - 비선형 활성화 함수는 복잡한 함수를 잘 반영할 수 있도록 만들어줌(다만 오버피팅 가능성이 높음)
- Tensorflow Playground에서 딥러닝 모델의 학습 메커니즘 정리해보기
  - https://playground.tensorflow.org/
- 손실(Loss) 함수의 이해와 크로스 엔트로피(Cross Entropy) 상세
  - 손실 함수
    - 손실 = 비용 = 목적
      - 전체 데이터의 실제 값과 예측 값의 차이 를 평균 한 값
    - 학습 결과인 예측값과 실제 값을 이용해서 학습과정이 올바르게 이뤄질 수 있도록 가이드 하는 역할 
    - 대표
      - 회귀 : MSE 사용 
      - 분류 : Cross Entropy Loss 
        - softmax, sigmoid 를 거쳐 예측 값을 출력 했을 때 나오는 확률 값을 실제값과 비교 하고 맞으면 끝나는 것 이 아니라, 맞는 예측 값의 크기를 키우기 위해 학습을 해야함 
          - soft max
            - 실제 클래스 값에 해당하는 Softmax의 결과 값에만 Loss를 부여함.
            - 아주 잘못된 예측 값 -> 매우 높은 로스(0) 부여 
            - 𝑪𝑬 = −𝒍𝒐𝒈(𝟐번째예측값)= −𝒍𝒐𝒈 𝟎. 𝟗 = 𝟎. 𝟏𝟎𝟓
              - 분류 클래스 중 2번째 클래스가 정답인 경우, 나머지 클래스들에 대한 실제 값은 0 이고, 클래스 2만 1 
              - 모든 예측 값을 다 더해봤자 클래스 2만 1을 곱하고 나머지는 0을 곱해서 0 
              - log(0.9) 는 음의 값 -> - 를 한번 더 곱함 
                - squared error 는 높은 비율 패널티로 loss 값 변화가 큼 -> 죄적 수렴 어려움, 또한 아주 잘못못된 예측에는 CE 보다 낮은 패널티
          - sigmoid 인 경우 
            - -(yi*log(^yi) + (1-yi)*log(l-^yi) )이 뒤에 붙는 이유 : 
              - 이진 분류 로 0 또는 1 -> 최종 출력층의 node 는 1개
              - ^y 는 시그모이드를 적용한 값
              - (1-yi) : 실제값이 1 이면 뒤에는 사라짐 
              - yi*log(^yi)  : 실제값이 0이면 사라짐 
        - Cross Entropy loss 에 기반 해서 Gradient Descent 를 계산 해서 업데이트 
          - multi class 
          - binary class 
- 옵티마이저(Optimizer)의 이해 - Momentum, AdaGrad
  - 최적으로 GD 를 적용해주는 것 : local minimum , Saddle point 의 방해를 물리치고 Global minimum 으로 갈 수 있도록
  - 주요 매커니즘 : 구렁텅이에 빠졌을 때 기어, 엑셀을 바꾸자! 
  - 주요 옵티마이저들 
    - Momentum
      - gradient 보정
      - 과거 gd를 반영 해서 새로운 Gradient 계산 ( 과거 GD 값은 가중치가 계속 작아지지만 어쩄든 계속 반영됨 ) -> 과거 떨어진 값을 반영해서 믿고 올라갈 수 있다
    - Adaptive Gradient 
      - learning rate 보정
      - 가중치 별로 서로 다른 Learning Rate를 적용 
      - 그동안 적게 변화된 가중치 -> 큰 LR, 많이 변화된 가중치는 -> 작은 LR
      - (그동안 적용된 GD 제곱 합 + 엡실론의 제곱근  을 사용)
      - 문제 : gd 의 제곱은 언제나 양이되므로 나중에는 lr이 아주 작아지는 문제 
      - 참고: 일반적인 lr 전략 - 처음에는 lr 를 크게 가다가 -> 학습이 진행 되면서 lr을 줄임 
    - RMSProp
      - learning rate 보정
      - lr 이 지나치게 작아지는 Adaptive Gradient의 단점을 보완 하기 위해 gd 제곱 값을 단순히 합하지 않고 지수가중 평균 법으로 구함
      - 너무 오랜 (?) gd 의 영향을 줄일 수 있도록 설정 
    
    - ADAM
      - GD + lR(Momentum + RMSProp) 모두 변경 
      - Momentum 을 지수가중평균 법으로 변경 
  - (참고) Learning Raate Scheduler 방식 : epoch 마다 동적으로 학습율 변경 
- Tensorflow 2.X 와 tf.keras 소개
  - Tensorflow 2.0 부터 keras 가 내부 패키지로 포함됨 
  - keras, tf.keras 함께 쓰지 말 것!
- 이미지 배열의 이해
  - n 차원 배열 : n-1 차원 배열이 여러개 있는 것 
  - Image 색상모델(RGB) 
    - Grayscale: 이미지 픽셀 값(0(B)~255(W) 으로 구성된 height * width 형태 2차원 배열 -> 여러장 묶음 ? ->  3차원! 
    - Color : R,G,B 등 의 채널 별 height * width 2차원 배열들이 있는 3차원 배열 -> 여러장 묶음 ? -> 4차원!
  - 정형 데이터 는 2차원으로 보통 표현
  - 딥러닝 의 경우 mini batch 로 데이터를 처리 -> 한번에 처리 해야함 -> 차원 관리(?)가 필요함 
- Dense Layer로 Fashion MNIST 예측 모델 구현하기 - 이미지 데이터 확인 및 사전 데이터 처리
  - 데이터 불러오기 (Keras fashion mnist dataset)
    - 6만장 중 학습 데이터 5만장/ 테스트 1만장 
    - grayscale -> 2차원 배열 -> input 3차원 배열 
  - 데이터 확인 
    - matplotlib.pyplot subplots 이용한 함수로 확인
  - 데이터 전처리 수행 
    - 0 ~255 사이 픽셀 값을 0 ~ 1 사이 값으로 변환 (데이터 계산을 쉽게 하기 위해) -> 픽셀 값을 255.0으로 나눠주면 0 ~ 1 로 변환 되지
    - array type = float 32 
  - Dense Layer를 기반으로 모델을 생성
    - 이 데이터 셋에서 Dense 를 사용해도 되는 이유: 
      - Dense 는 1차원 적인 입력 밖에 못받아들임 -> 이미지 분류 성능이 떨어짐 
      - 하지만 이번 실습의 경우 이미지가 가운데 분명하게 나와있기 때문에 Dense 로 해도 무리 없음! 
    - 각 픽셀 값(28*28 = 784)을 입력 feature 으로 받음 (Flatten)
    - -> Dense layer (weighted sum, activation(ReLU) 까지 포함 => out 까지 만듬) - 100개 뉴런 , weight = 784 * 100 + bias 100
    - -> Dense layer (weighted sum, activation(ReLU) 까지 포함 => out 까지 만듬) - 30개 뉴런, weight =  100* 30 + bias 30
    - -> soft max - 10개 뉴런 , weight = 30 *10 + bias 10
  - 모델의 Loss와 Optimizer 설정하고 학습 수행
    - loss는 categorical_crossentropy(다중 분류 손실함수)  lable -> one-hot encoding로, optimizer는 Adam으로 설정
    - categorical crossentropy를 위해서 Lable을 OHE 로 변경
    - 차원에 대한 명확한 이해가 필요! 
    - 배치는 프레임워크가 알아서 하는 것!, 다만 배치까지 고려하고 인풋 형태를 정함 
  - 예측 및 성능 평가
    - 테스트 데이터를 기반으로 Label 값 예측 
      - label : 0 ~ 9 
      - predict 할 때 주의할 점 ! 
        - 차원 맞추기! 
          - 실제로 모델은 2차원의 배열을 분석하지만, 인풋으로 넣을때는 배치로 들어올 것 을 예상하고 만들어져있으므로 차원을 늘려줘야함 
          - np.expand_dims 을 사용해서 차원을 늘려주고, 돌려받은 softmax 결과 값에서 다시 np.squeeze
    - 테스트 데이터 세트로 모델 성능 검증
      - model.evaluate one-hot encoding 된 것을 넣자 
    - 검증 데이터를 활용하여 학습 수행
      - 훈련 데이터 셋으로 반복해서 성능 개선 하는 것이므로 훈련 데이터 셋에만 최적화된 학습이 될 수 있음 (과적합)
      - 학습을 제대로 하고 있는지 확인 하기 위해 검증 데이터 셋을 활용 
        - fit 을 수행하면 iteration 을 반복하믄로 중간에 하이퍼파라미터를 변경 할 수 없음
        - 그래서 콜백 객체를 가짐 
        - 콜백 객체는 학습 데이터가 아닌 검증 데이터 셋으로 모니터링! 
        - 그래서 학습시 훈련 데이터와 검증 데이터셋을 함께 돌려야함
        - 검증 fit 
          - sklearn의 train_test_split으로 데이터를 훈련 데이터 셋과 검증 셋으로 나눠주기 
          - target data 에 OHE 적용 
          - model 만들기 
            - Sequential, compile 은 아까 와 동일
          - model.fit
            - validation_data=(val_images, val_oh_labels)
    - Functional API 이용하여 모델 만들기
      - Sequential 로 만드는 모델 문제 
        - functional api 를 쉽게 적용하여 모델을 만들어주는 유틸리티 
        - input 을 정하기 애매함 왜냐하면 sequential 은 레이어로 구성되어있는데 input은 레이어라고 하기 어려움 -> 구별하기 어려움 ==> input_shape로 알려줌
      - Functional API 필요성 
        - Deep learning 은 각 레이어 마다 이전의 결과 값을 입력으로 받아서 처리하는 chain 형태 로직,
        - functional api 는 객체에 입력 값을 받아서 결과로 저장, 다시 새로운 객체의 입력 값으로 사용하는 형태로 러닝 매커니즘을 직관적으로 보여줄 수 있음 
      - 사용법 
        - Model 클래스 불러오기 
        - Input 명시 - 거듭강조 : Input의 shape 는 input의 개수가 아니고, 들어오는 각각 input 배열의 모양 
        - Flatten(생성파라미터) 객체 + 인자 입력 
  - Keras Layer API 개요
    - layer 는 주요 api 
    - lay 유형
      - core
        - dense 
        - activation 등등 
      - convolution
      - layer 는 대문자로 시작하는게 보통 
  - Keras Callback 개요
    - Callback : 루프가 돌때마다 생기는 이벤트마다 callback 을 호출 -> 루프시에 뭔가 작업을 할 수 있게 만들어줌
    - callback 을 호출 할 수 있는 모듈에 등록 해놓고, 모듈에서 이벤트 발생 시 마다 callback 호출
    - keras callback -> 주로 learing rate 컨트롤할 때 사용 
      - ModelCheckpoint()
        - #### ModelCheckpoint(filepath, monitor='val_loss', verbose=0, save_best_only=False, save_weights_only=False, mode='auto', period=1)
          - fit 하는 과정동안 모델링 결과를 중간 중간 계속 저장 하도록 함 
            - 특정 조건에 맞춰서 모델을 파일로 저장
              * filepath: filepath는 (on_epoch_end에서 전달되는) epoch의 값과 logs의 키로 채워진 이름 형식 옵션을 가질 수 있음.
                예를 들어 filepath가 weights.{epoch:02d}-{val_loss:.2f}.hdf5라면, 파일 이름에 세대 번호와 검증 손실을 넣어 모델의 체크포인트가 저장
              * monitor: 모니터할 지표(loss 또는 평가 지표) -> 검증 데이터(loss, accuracy)의 테스트 값이 작아지는지 모니터링 
              * save_best_only: 가장 좋은 성능을 나타내는 모델만 저장할 여부 
              * save_weights_only: Weights만 저장할 지 여부 -> 왠만 하면 True 로 선택하는 것이 좋음(TF 에서 잘 풀어내지 못할 수도 있기때문에 )
              * mode: {auto, min, max} 중 하나. monitor 지표가 감소해야 좋을 경우 min, 증가해야 좋을 경우 max, auto는 monitor 이름에서 자동으로 유추(커버를 잘 하지 못할 수도).
      - ReducedLROnPlateau()
        - #### ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=10, verbose=0, mode='auto', min_delta=0.0001, cooldown=0, min_lr=0)
          - 특정 epochs 횟수동안 성능이 개선 되지 않을 시 Learning rate를 동적으로 감소 시킴
            * monitor: 모니터할 지표(loss 또는 평가 지표)
            * factor: 학습 속도를 줄일 인수. new_lr = lr * factor
            * patience: Learing Rate를 줄이기 전에 monitor할 epochs 횟수.
            * mode: {auto, min, max} 중 하나. monitor 지표가 감소해야 좋을 경우 min, 증가해야 좋을 경우 max, auto는 monitor 이름에서 유추.
      - LearningRateScheduler()
      - EarlyStopping()
        - #### EarlyStopping(monitor='val_loss', min_delta=0, patience=0, verbose=0, mode='auto', baseline=None, restore_best_weights=False)
          * 특정 epochs 동안 성능이 개선되지 않을 시 학습을 조기에 중단
          * monitor: 모니터할 지표(loss 또는 평가 지표)
          * patience: Early Stopping 적용 전에 monitor할 epochs 횟수.
          * mode: {auto, min, max} 중 하나. monitor 지표가 감소해야 좋을 경우 min, 증가해야 좋을 경우 max, auto는 monitor 이름에서 유추.
      - 등등 
- Numpy array와 Tensor 차이, 그리고 fit() 메소드 상세 설명
  - Numpy : 딥러닝 뼈대 ! 선형 대수 관련 아주 강력한 연산 지원 
    - cpu simd(명령 한번으로 여러 데이터 한번에 계산 ) 기능을 최적으로 사용할 수 있음
  - Numpy array와 Tensor 차이
    - 논리적으로는 같은 의미 
    - (참고) 숫자 = scalar , 1차원 행렬 = vector, 2d = matrix, 3d ~ = Tensor
    - 차이
      - Numpy array 
        - CPU에 기반해서 동작 (GPU 를 지원하지 않음), 
        - 보다 범용적인 영역 
      - Tensor :
        - CPU + GPU 
        - 딥러닝을 위한 기능들이 추가됨
        - 범용적인 영역으로 확장 중 
  - Tensor 
    - Numpy 와 유사한 interface 를 가지고 있음 
    - fit 할 떄 input 으로 넣는 것은 np array 이지만, 
    - 모델 만들 때 input 으로 들어가는 것은 모두 Tensor 