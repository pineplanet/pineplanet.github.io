---
title: TIL 2022-01-24 python 머신러닝 
tags: [TIL, python]
categories: TIL
---

# 오늘 배운 것 

- 머신러닝 
  - 1 로지스틱 회귀 ▶️로지스틱 회귀 알고리즘을 배우고 이진 분류 문제에서 클래스 확률 예측하기
    - 럭키백의 확률
      - 확률 : 분류 확신 (회귀 문제 아님)
        - k-최근접 : 이웃 샘플이 10개 일 때 클래스 비율 => 확률로 출력 (이웃의 수가 확률이 되니, 단순함)
        
    - 로지스틱 회귀
      - 인공 신경망의 기초재료 
      - '회귀' 라고 하지만 분류 알고리즘
      - 시그모이드 함수(로지스틱 함수) : 확률 뽑아내기
          - 무한대 -> 0 ~ 1.0 
          - 0.5 를 기준으로 작으면 음성, 크면 양성 
          - from scipy.special import expit 로 계산
      - z 값으로도 양,음성 판단 할 수 있음 
      - 이진 분류 
        - 양성 클래스에 대한 z 값 만 계산 
        - 위 값을 빼면 음성클래스 확률 값
      - 다중 분류
        - 반복적인 알고리즘을 사용(max_iter로 반복 횟수 조정 )
        - l2 노름 규제를 기본 적용(C 값으로 조정하는데, C 값이 높을수록 규제가 약해지고 , 낮을수록 규제가 강해짐)
        - 클래스마다 z  값이 하나씩 나옴 
        - 이진 분류를 현재 클래스 VS 나머지 클래스로 나눠서 함 (one versus rot)
        - z - > 시그모이드 로 바꾸면 전체 시그모이드의 합은 1 
          - softmax 함수를 사용한다. 
          - 각 샘플 - >  z값을 지수 함수에 적용 , 전체 sum 한 다음  각 지수함수를 분모로 나눠줌 
  
      